{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>A collection of unexpected challenges and learnings with nextflow and nf-core. The provided examples reflect my journey in learning nextflow and generally assume an intermediate familiarity with nextflow.</p>"},{"location":"#gotchas","title":"Gotchas","text":"<p>The gotchas are typically provided as minimal, reproducible examples (MREs) with additional explanations. What is a minimal, reproducible example?</p> <p>As explained very well on StackOverflow:</p> <p>Your code examples should be</p> <ul> <li>Minimal \u2013 Use as little code as possible that still produces the same problem</li> <li>Complete \u2013 Provide all parts someone else needs to reproduce your problem in the question itself</li> <li>Reproducible \u2013 Test the code you're about to provide to make sure it reproduces the problem</li> </ul>"},{"location":"#errors","title":"Errors","text":"<p>Nextflow error messages and stack traces can, in all honesty, be quite maddening. Hopefully, yours is among the common ones that we describe here.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are most welcome and I very much aim for this to be a community-driven project. In fact, most of the solutions provided here came from discussions on the nextflow or nf-core Slack. Both are incredible communities and I can only recommend that you join. Phil Ewels and I are already talking about how to best integrate these examples into the nf-core website. Please open an issue on the repository or message me on either of the Slack teams linked in the footer regarding any examples, ideas, or suggestions that you may have.</p>"},{"location":"#contributors","title":"Contributors \u2728","text":"<p>Thanks go to these wonderful people (emoji key):</p> FriederikeHanssen\ud83d\udcd6 \ud83d\udca1 James A. Fellows Yates\ud83d\udcd6 \ud83d\udca1 Simon Pearce\ud83d\udcd6 \ud83d\udca1 <p>This project follows the all-contributors specification. Contributions of any kind welcome!</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>As mentioned, nextflow has an amazing community. I want to mention a few people here who have been especially helpful in my interactions. In alphabetical order:</p> <ul> <li>Friederike Hanssen</li> <li>Harshil Patel</li> <li>Jose Espinosa-Carrasco</li> <li>Mahesh Binzer-Panchal</li> <li>Maxime U. Garcia</li> <li>Phil Ewels</li> <li>Pontus Freyhult</li> <li>Robert Syme</li> </ul> <p>If you feel that I forgot you in this list. Please let me know, it's not intentional!</p>"},{"location":"#copyright","title":"Copyright","text":"<p>All examples and descriptions are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License.</p>"},{"location":"errors/","title":"Introduction","text":"<p>Error messages and stack traces are probably the most intimidating whenever you start a new programming language. However, with nextflow there is an extra level of grief associated with coding errors. Nextflow is a domain specific language (DSL) for defining workflows built in Groovy/Java. That means that all the files actually are parsed and executed as Java code under the hood.</p> <p>In my experience, error messages and stack traces only vaguely point you in the direction of your mistakes and just as often confuse you more than they help you. As an example, I was working on a pipeline and forgot a comma in a configuration file.</p> <pre><code>pipeline\n\u251c\u2500\u2500 conf\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 modules.config  # (1)\n\u2514\u2500\u2500 nextflow.config  # (2)\n</code></pre> <ol> <li> <p>Here, I had forgotten a comma when configuring a process.</p> <pre><code>process {\nwithName: PROCESS {\npublishDir = [\nmode: 'copy'\npattern: '*.txt'\n]\n}\n}\n</code></pre> </li> <li> <p>The <code>nextflow.config</code> includes the <code>conf/modules.config</code>:</p> <pre><code>includeConfig 'conf/modules.config'\n</code></pre> </li> </ol> <p>The error message that I got looked something like:</p> <pre><code>Unable to parse config file: 'pipeline/nextflow.config'\n  Compile failed for sources FixedSetSources[name='/groovy/script/Script804F3A5DC10BC08232AE23542F1477EC']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:\n  /groovy/script/Script804F3A5DC10BC08232AE23542F1477EC: 1: Unexpected input: '{' @ line 1, column 9.\n     process {\n             ^\n  1 error\n</code></pre> <p>So I knew it had to be a mistake inside of the <code>process</code> scope somewhere but that's not very helpful when I have several nested configuration files that each modify the <code>process</code> scope and I don't know what kind of error.</p> <p>Hopefully, the examples provided in the errors section can help you make sense of your own cryptic messages.  Most of them are contributions from nf-core hackathon documentation.</p>"},{"location":"errors/dataflowvariable-assigned-once/","title":"DataflowVariable can only be assigned once","text":""},{"location":"errors/dataflowvariable-assigned-once/#issue","title":"Issue","text":"<p>You get the following error, connected to a process</p> <pre><code>Error executing process &gt; 'PROCESS'\nCaused by:\n  A DataflowVariable can only be assigned once. Only re-assignments to an equal value are allowed.\n</code></pre>"},{"location":"errors/dataflowvariable-assigned-once/#possible-source","title":"Possible source","text":"<p>You forgot the parentheses around a function like <code>flatten()</code>:</p> <pre><code>PROCESS\n.out\n.vcfs\n.flatten\n</code></pre>"},{"location":"errors/dump-missing/","title":"Missing process or function with name dump","text":""},{"location":"errors/dump-missing/#issue","title":"Issue","text":"<p>When using the <code>.dump()</code> function you get an error to console</p> <pre><code>Missing process or function with name 'dump'\n</code></pre>"},{"location":"errors/dump-missing/#possible-source","title":"Possible source","text":"<p>In many cases, the function is not missing, just incorrectly applied.</p> <ul> <li>Missing <code>tag:</code> before the actual tag name (e.g. <code>.dump('my tag') vs .dump(tag: 'my_tag')</code>)</li> <li>Placed on a channel-type that does not support the <code>.dump</code> function (e.g. channels with branches)</li> <li><code>.dump()</code> was applied on a multi-channel output object without specifying which channel</li> <li><code>.dump()</code> was applied on a single-channel, unnamed output directly. Usually, when a process defines a single output, unnamed channel, <code>PROCESS_NAME.out</code> (without specifying <code>[0]</code>) works well with various nextflow operators, but, surprisingly, this way does not work well the <code>dump</code> operator.  Quick workarounds could be i) using <code>[0]</code> to specify the channel explicitly, e.g. <code>PROCESS_NAME.out[0]</code>, ii) using named output, or iii) use a <code>map</code> operator before the <code>dump</code> operator. Examples can be  found in issue #3</li> </ul>"},{"location":"errors/id-null-object/","title":"Cannot get property id on null object","text":""},{"location":"errors/id-null-object/#issue","title":"Issue","text":"<p>Console</p> <pre><code>Execution aborted due to an unexpected error\n -- Check script '/home/jfellows/Documents/git/nf-core/taxprofiler/./workflows/../modules/nf-core/modules/kraken2/kraken2/main.nf' at line: 2 or see '.nextflow.log' file for more details\n</code></pre> <p>Log</p> <pre><code>java.lang.NullPointerException: Cannot get property 'id' on null object\n</code></pre>"},{"location":"errors/id-null-object/#possible-source","title":"Possible source","text":"<p>In most cases <code>meta.id</code> does exist, it is just not accessible by Nextflow in the way it expects to.</p> <ul> <li>Input channels not correctly passed to a module<ul> <li><code>meta</code> tuple is incorrectly nested (e.g. <code>[[&lt;meta&gt;]]</code> vs. <code>[&lt;meta&gt;]</code>)</li> <li>Other parts of an input channel are incorrectly nested e.g. <code>[meta] [[reads1.fq, reads2.fq]]</code> when should be <code>[meta] [reads1.fq, reads2.fq]</code></li> </ul> </li> <li>Two separate input channels both have a <code>meta.id</code> tag (i.e., Nextflow doesn't know which one to take).</li> <li>Can also occur when <code>meta.id</code> tag is specified the <code>tag</code> block of a module, but <code>meta</code> is not supplied as input.</li> </ul>"},{"location":"errors/invalid-method-invocation-call/","title":"Invalid method invocation with arguments","text":""},{"location":"errors/invalid-method-invocation-call/#issue","title":"Issue","text":"<p>You get an error such as:</p> <pre><code>ERROR ~ Invalid method invocation `call` with arguments: [i, am, a] (java.util.ArrayList) on _runScript_closure1 type  # (1)!\n-- Check '.nextflow-console.log' file for details\n</code></pre> <ol> <li>Note that <code>call</code> can sometimes be reported as <code>doCall</code>.</li> </ol>"},{"location":"errors/invalid-method-invocation-call/#possible-source","title":"Possible source","text":"<p>This normally means you are using a closure (e.g., within a map call) on a channel somewhere in your workflow in which you define variables for each element of the input channel.</p> <p>You will get the error if the input channel has additional or fewer elements than defined in the closure function.</p> <pre><code>ch_input = Channel.of(['foo', 'bar', 'baz'])\n\nch_input.map{ one, two -&gt; [one] }\n</code></pre> <p>or</p> <pre><code>ch_input = Channel.of(['foo'])\n\nch_input.map{ one, two -&gt; [one] }\n</code></pre>"},{"location":"errors/invalid-method-invocation-call/#solution","title":"Solution","text":"<p>To fix, ensure that whenever you define variables to elements there is a one to one ratio of variable names to elements</p> <pre><code>ch_input = Channel.of(['foo', 'bar', 'baz'])\n\nch_input.map{ one, two, three -&gt; [one] }\n</code></pre> <p>Note that the error message does not report where this happens, so you will have to look for all cases of a closure being applied to the channel with the channel contents as reported in the error, to find where this occurs. Liberal use of the dump channel operator can help you spot a mismatch between expected and actual channel content.</p>"},{"location":"errors/mix-missing/","title":"Missing process or function with name mix","text":""},{"location":"errors/mix-missing/#issue","title":"Issue","text":"<p>You get the follow error when using <code>.mix()</code> on channels</p> <pre><code>Missing process or function with name 'mix'\n</code></pre>"},{"location":"errors/mix-missing/#possible-source","title":"Possible source","text":"<ul> <li> <p>You passed a multi-channel output variable to <code>.mix</code> that causes this error:</p> <pre><code>ch_scaffolds2bin_for_dastool\n.mix(DASTOOL_SCAFFOLDS2BIN_METABAT2.out.scaffolds2bin)\n.mix(DASTOOL_SCAFFOLDS2BIN_MAXBIN2)\n</code></pre> <p>when you should've specified the particular <code>.out</code> channels</p> <pre><code>ch_scaffolds2bin_for_dastool\n.mix(DASTOOL_SCAFFOLDS2BIN_METABAT2.out.scaffolds2bin)\n.mix(DASTOOL_SCAFFOLDS2BIN_MAXBIN2.out.scaffolds2bin)\n</code></pre> </li> </ul>"},{"location":"errors/module-compilation/","title":"Module compilation error","text":""},{"location":"errors/module-compilation/#issue","title":"Issue","text":"<p>You get the following error, connected to the whole workflow</p> <pre><code> - file : [PATH]\n -  cause: Unexpected input: '{' @ line N, column N.\n -  workflow [WORKFLOW] {\n</code></pre>"},{"location":"errors/module-compilation/#possible-source","title":"Possible source","text":"<ul> <li> <p>You put two <code>.</code> next to each other, such as at the end of the first line and the start of the second:</p> <pre><code>PROCESS.\n.out\n.bam\n.set{ch_bams}\n</code></pre> </li> </ul>"},{"location":"errors/multi-channel-operator/","title":"Multi-channel output cannot be applied to operator for which argument is already provided","text":""},{"location":"errors/multi-channel-operator/#issue","title":"Issue","text":"<p>You get an error such as</p> <pre><code>Multi-channel output cannot be applied to operator mix for which argument is already provided\n</code></pre>"},{"location":"errors/multi-channel-operator/#possible-source","title":"Possible source","text":"<p>You likely forgot to specify the output channel of a multi-channel output module or subworkflow, i.e.,</p> <pre><code>ch_output = MODULE_A ( input )\nMODULE_B ( ch_output )\n</code></pre> <p>should be</p> <pre><code>ch_output = MODULE_A ( input ).reads\nMODULE_B ( ch_output )\n</code></pre>"},{"location":"errors/unable-parse-config/","title":"Unable to parse config file","text":""},{"location":"errors/unable-parse-config/#issue","title":"Issue","text":"<pre><code>Unable to parse config file: 'nextflow.config'\nCompile failed for sources FixedSetSources[name='/groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:\n/groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A: 432: Unexpected input: '{' @ line 432, column 8.\n    process{\n           ^\n</code></pre>"},{"location":"errors/unable-parse-config/#possible-source","title":"Possible source","text":"<p>Syntax error in <code>modules.config</code>, such as:</p> <ol> <li>Missing comma in <code>publishDir</code></li> <li>Additional <code>=</code> after <code>ext.&lt;&gt;</code> directive</li> <li>Missing <code>{</code> or <code>}</code> somewhere</li> </ol> <p>Mentioned line numbers OR mentioned sign are not indicative of where to search for the error, i.e., in the above example the actual problem was a duplicated <code>=</code>.</p>"},{"location":"gotchas/combine-list/","title":"Combine a list element","text":""},{"location":"gotchas/combine-list/#problem","title":"Problem","text":"<p>Say that you have a tool which takes a parameter and a bunch of files and does something with those. This is exemplified by the process <code>CAT</code> below. My first approach was to <code>collect</code> the files before combining them with the parameter. See the following workflow as an example.</p> problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess CREATE {\ninput:\nval filename\noutput:\npath filename\nscript:  // (1)\n\"\"\"\n    echo ${filename} &gt; ${filename}\n    \"\"\"\n}\nprocess CAT {\ninput:\ntuple val(number), path(files)\noutput:\ntuple val(number), path('result.txt')\nscript:  // (2)\n\"\"\"\n    cat ${files} &gt; result.txt\n    echo 'Parameter: ${number}' &gt;&gt; result.txt\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_param = Channel.of(1..5)\nch_files = Channel.of('foo.txt', 'bar.txt', 'baz.txt')\nCREATE(ch_files)\nCREATE.out.map { it.name } .view()  // (3)\nch_input = ch_param.combine( CREATE.out.collect() )  // (4)\nch_input.map { row -&gt;\n[row.head()] + row.tail().collect{ it.name }  // (5)\n}\n.view()\nCAT(ch_input)\nCAT.out.map { it[1].text }.view()  // (6)\n}\n</code></pre> <ol> <li>Create a file with distinct content.</li> <li>Concatenate all files into one and use the parameter value.</li> <li>For better display, I'm only showing the filenames here and not the whole paths.</li> <li>The <code>collect</code> operator should turn this into a list.</li> <li>Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths.</li> <li>Here, I want to show the content of the resulting file which is the second of the pair in the output.</li> </ol> <p>Run the above workflow with:</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/combine-list/problem.nf\n</code></pre> <p>which gives the following output. It looks like the <code>combine</code> operator, when combining a single list of elements treats that just like a channel and forms the cartesian product with every element. There is also a warning about the input cardinality not matching the defined one in <code>CAT</code> and indeed we can see in the output that only one file is written to the result while the others are ignored.</p> <pre><code>executor &gt;  local (8)\n[32/a72ef8] process &gt; CREATE (1) [100%] 3 of 3 \u2714\n[0a/dfd2e7] process &gt; CAT (4)    [100%] 5 of 5 \u2714\nbaz.txt\nbar.txt\nfoo.txt\n[1, baz.txt, bar.txt, foo.txt]\n[2, baz.txt, bar.txt, foo.txt]\n[3, baz.txt, bar.txt, foo.txt]\n[4, baz.txt, bar.txt, foo.txt]\n[5, baz.txt, bar.txt, foo.txt]\nbaz.txt\nParameter: 1\nbaz.txt\nParameter: 5\nbaz.txt\nParameter: 2\nbaz.txt\nParameter: 3\nbaz.txt\nParameter: 4\nWARN: Input tuple does not match input set cardinality declared by process `CAT`\n</code></pre>"},{"location":"gotchas/combine-list/#solution","title":"Solution","text":"<p>Well, if a single list gets treated just like a channel, maybe we can nest that list such that we have a list with a single element that is also a list. I tried quite a few different ways:</p> <ol> <li> <p>Can we collect twice?</p> <pre><code>ch_input = ch_param.combine( CREATE.out.collect().collect() )\n</code></pre> <p>This does not work correctly. Just like in the problem, we get a flat list.</p> </li> <li> <p>What if we place it into a list manually?</p> <pre><code>ch_input = ch_param.combine( [ CREATE.out.collect() ] )\n</code></pre> <p>This yields an error</p> <pre><code>Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable\n</code></pre> <p>which makes sense since we place the collected variable (of type <code>DataflowVariable</code>) inside the literal list and thus it gets passed to our <code>CAT</code> process directly.</p> </li> <li> <p>Instead of <code>collect</code> there is also <code>toList</code>...</p> <pre><code>ch_input = ch_param.combine( [ CREATE.out.toList() ] )\n</code></pre> <p>Same error </p> <pre><code>Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable\n</code></pre> </li> <li> <p>Then I got the correct advice:</p> <pre><code>ch_input = ch_param.combine( CREATE.out.toList().toList() )\n</code></pre> <p>The corresponding comment on Slack was:</p> <p>Harshil Patel</p> <p>Don't ask me why.</p> <p> </p> </li> <li> <p>Turns out that the following combination also works.</p> <pre><code>ch_input = ch_param.combine( CREATE.out.collect().toList() )\n</code></pre> </li> </ol> <p>So in full the solution looks as follows.</p> solution.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess CREATE {\ninput:\nval filename\noutput:\npath filename\nscript:  // (1)\n\"\"\"\n    echo ${filename} &gt; ${filename}\n    \"\"\"\n}\nprocess CAT {\ninput:\ntuple val(number), path(files)\noutput:\ntuple val(number), path('result.txt')\nscript:  // (2)\n\"\"\"\n    cat ${files} &gt; result.txt\n    echo 'Parameter: ${number}' &gt;&gt; result.txt\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_param = Channel.of(1..5)\nch_files = Channel.of('foo.txt', 'bar.txt', 'baz.txt')\nCREATE(ch_files)\nCREATE.out.map { it.name } .view()  // (3)\nch_input = ch_param.combine( CREATE.out.toList().toList() )  // (4)\nch_input.map { row -&gt;\n[row.head(), row.last().collect{ it.name }]  // (5)\n}\n.view()\nCAT(ch_input)\nCAT.out.map { it[1].text }.view()  // (6)\n}\n</code></pre> <ol> <li>Create a file with distinct content.</li> <li>Concatenate all files into one and use the parameter value.</li> <li>For better display, I'm only showing the filenames here and not the whole paths.</li> <li>Use the winning solution from above. The <code>toList</code> operator applied twice creates the nested list.</li> <li>Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths.</li> <li>Again, I want to show the content of the resulting file which is the second of the pair in the output.</li> </ol> <p>Run the above workflow with:</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/combine-list/solution.nf\n</code></pre> <p>This time, both the shape of the input for <code>CAT</code>, as well as the content of the resulting files are as expected. </p> <pre><code>executor &gt;  local (8)\n[0c/731285] process &gt; CREATE (3) [100%] 3 of 3 \u2714\n[e0/670c78] process &gt; CAT (5)    [100%] 5 of 5 \u2714\nbar.txt\nfoo.txt\nbaz.txt\n[1, [bar.txt, foo.txt, baz.txt]]\n[2, [bar.txt, foo.txt, baz.txt]]\n[3, [bar.txt, foo.txt, baz.txt]]\n[4, [bar.txt, foo.txt, baz.txt]]\n[5, [bar.txt, foo.txt, baz.txt]]\nbar.txt\nfoo.txt\nbaz.txt\nParameter: 3\nbar.txt\nfoo.txt\nbaz.txt\nParameter: 1\nbar.txt\nfoo.txt\nbaz.txt\nParameter: 4\nbar.txt\nfoo.txt\nbaz.txt\nParameter: 2\nbar.txt\nfoo.txt\nbaz.txt\nParameter: 5\n</code></pre>"},{"location":"gotchas/combine-list/#alternative-solutions","title":"Alternative solutions","text":""},{"location":"gotchas/combine-list/#dataflowvariable-value","title":"DataflowVariable value","text":"<p>We saw above that the following code caused an error because we are passing a <code>groovyx.gpars.dataflow.DataflowVariable</code> to the process.</p> <pre><code>ch_input = ch_param.combine( [ CREATE.out.collect() ] )\n</code></pre> <p>It is possible, though highly discouraged, to access a <code>DataflowVariable</code>'s inner value.</p> <pre><code>ch_input = ch_param.combine( [ CREATE.out.collect() ] )  // (1)\n.map { first, second -&gt; [first, second.val] }\n</code></pre> <ol> <li>This combination generates pairs where the first element is the <code>val</code> and the second the <code>DataflowVariable</code> containing the list.</li> </ol>"},{"location":"gotchas/combine-list/#creating-a-list-through-transformation","title":"Creating a list through transformation","text":"<p>In our problem statement we saw:</p> <pre><code>ch_input = ch_param.combine( CREATE.out.collect() )\n</code></pre> <p>which created lists of four elements each. The parameter and the three files. We can transform this shape ourselves.</p> <pre><code>ch_input = ch_param.combine( CREATE.out.collect() )\n.map { [it.head(), it.tail()] }\n</code></pre> <p>Done </p>"},{"location":"gotchas/combine-list/#using-combine-and-grouptuple","title":"Using combine and groupTuple","text":"<p>A very different approach is to first combine every parameter value with every file. This generates pairs of one value and one file. We can then group the pairs together as tuples.</p> group-tuple.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess CREATE {\ninput:\nval filename\noutput:\npath filename\nscript:  // (1)\n\"\"\"\n    echo ${filename} &gt; ${filename}\n    \"\"\"\n}\nprocess CAT {\ninput:\ntuple val(number), path(files)\noutput:\ntuple val(number), path('result.txt')\nscript:  // (2)\n\"\"\"\n    cat ${files} &gt; result.txt\n    echo 'Parameter: ${number}' &gt;&gt; result.txt\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_param = Channel.of(1..5)\nch_files = Channel.of('foo.txt', 'bar.txt', 'baz.txt')\nCREATE(ch_files)\nCREATE.out.map { it.name } .view()  // (3)\nch_input = ch_param.combine( CREATE.out )  // (4)\n.groupTuple()\nch_input.map { row -&gt;\n[row.head(), row.last().collect{ it.name }]  // (5)\n}\n.view()\nCAT(ch_input)\nCAT.out.map { it[1].text }.view()  // (6)\n}\n</code></pre> <ol> <li>Create a file with distinct content.</li> <li>Concatenate all files into one and use the parameter value.</li> <li>For better display, I'm only showing the filenames here and not the whole paths.</li> <li>Use <code>combine</code> on the flat channels to generate pairs. Then collect tuples of files by grouping the pairs by their first element, the numeric value, with <code>groupTuple</code>.</li> <li>Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths.</li> <li>Again, I want to show the content of the resulting file which is the second of the pair in the output.</li> </ol> <p>Run it</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/combine-list/group-tuple.nf\n</code></pre> <p>This generates the exact same solution. However, if you have a lot of elements in your channels this might perform slightly worse since you generate a lot more pairs first that you then have to group again.</p> <pre><code>executor &gt;  local (8)\n[e9/c7a72b] process &gt; CREATE (2) [100%] 3 of 3 \u2714\n[cb/44c510] process &gt; CAT (5)    [100%] 5 of 5 \u2714\nbaz.txt\nfoo.txt\nbar.txt\n[1, [baz.txt, foo.txt, bar.txt]]\n[2, [baz.txt, foo.txt, bar.txt]]\n[3, [baz.txt, foo.txt, bar.txt]]\n[4, [baz.txt, foo.txt, bar.txt]]\n[5, [baz.txt, foo.txt, bar.txt]]\nbaz.txt\nfoo.txt\nbar.txt\nParameter: 4\nbaz.txt\nfoo.txt\nbar.txt\nParameter: 2\nbaz.txt\nfoo.txt\nbar.txt\nParameter: 3\nbaz.txt\nfoo.txt\nbar.txt\nParameter: 1\nbaz.txt\nfoo.txt\nbar.txt\nParameter: 5\n</code></pre>"},{"location":"gotchas/join-on-map-fails-resume/","title":"Joining channels using a map as key","text":""},{"location":"gotchas/join-on-map-fails-resume/#problem","title":"Problem","text":"<p>You want to <code>join</code> two channels using identical maps as the key to join by.</p> examples/join-on-map-fails-resume/problem.nf<pre><code>left = LEFT(ch_param)  // (1)\nright = RIGHT(ch_param)  // (2)\nch_joined = left.join(right)  // (3)\n</code></pre> <ol> <li>A channel that contains a pair of a map with sample meta information and a number.     <pre><code>tuple val(meta), val(count)\n</code></pre></li> <li>A channel that contains a pair of a map with sample meta information and a list of file paths.     <pre><code>tuple val(meta), path(reads)\n</code></pre></li> <li>The desired joined channel should contain the map, the number, and the file paths.     <pre><code>tuple val(meta), val(count), path(read_pairs)\n</code></pre></li> </ol> <p>This will work perfectly fine when you execute your workflow from the beginning. However, when you resume your workflow, you will likely see that from the point of such a join statement, many samples are dropped from further processing since the maps no longer evaluate as being equal and thus the tuples are discarded as being incomplete. You can avoid elements being silently discarded by using the <code>failOnMismatch</code> option.</p> examples/join-on-map-fails-resume/problem.nf<pre><code>left = LEFT(ch_param)\nright = RIGHT(ch_param)\nch_joined = left.join(right, failOnMismatch: true)\n</code></pre>"},{"location":"gotchas/join-on-map-fails-resume/#solution","title":"Solution","text":"<p>Since maps, as mutable objects, may fail to evaluate as being equal after resuming1, we can pull out an immutable value from the maps and join on them. Your map likely contains an <code>id</code> key which is a unique string or integer that is equal in both channels to be joined. This requires a couple of channel transformations such that we end up with the resulting channel containing the desired map as first element, followed by the remaining elements from both joined channels.</p> examples/join-on-map-fails-resume/solution.nf<pre><code>def left = LEFT(ch_param).map { [it[0].id, it[0], it[1]] }  // (1)\ndef right = RIGHT(ch_param).map { [it[0].id, it[0], it[1]] }  // (2)\ndef ch_joined = left.join(right).map { [it[1], it[2], it[4]] }  // (3)\n</code></pre> <ol> <li>We prepend the <code>id</code> key which contains an immutable value.     <pre><code>tuple val(id), val(meta), val(count)\n</code></pre></li> <li>We prepend the <code>id</code> key which contains an immutable value.     <pre><code>tuple val(id), val(meta), path(reads)\n</code></pre></li> <li>After the join that occurred on the <code>id</code> value, we remove that element and also drop one of the otherwise identical maps.     <pre><code>tuple val(meta), val(count), path(read_pairs)\n</code></pre></li> </ol> <p>In order to generally, safely join two channels on a map key, I therefore propose you use the following function which was developed together with  Mahesh Binzer-Panchal</p> lib/CustomChannelOperators.groovy<pre><code>/**\n * Provide a collection of custom channel operators that go beyond the nextflow default.\n */\nclass CustomChannelOperators {\n/**\n     * Join two channels by one or more keys from a map contained in each channel.\n     *\n     * The channel elements are assumed to be tuples whose size is at least two.\n     * Typically, the maps to join by are in the first position of the tuples.\n     * Please read https://www.nextflow.io/docs/latest/operator.html#join carefully.\n     *\n     * @param args A map of keyword arguments that is passed on to the nextflow join call.\n     * @param left The left-hand side channel in the join.\n     * @param right The right-hand side channel in the join.\n     * @param key A string or list of strings providing the map keys to compare.\n     * @param leftBy The position of the map in the left channel.\n     * @param rightBy The position of the map in the right channel.\n     * @return The joined channels with the map in the original position of the left channel,\n     *      followed by all elements of the right channel except for the map.\n     */\npublic static Object joinOnKeys(\nMap joinArgs = [:],\nleft,\nright,\nkey,\nint leftBy = 0,\nint rightBy = 0\n) {\nList keys = key instanceof List ? key : [ key ]\n// Extract desired keys from the left map, located at `leftBy`, and prepend them.\ndef newLeft = left.map { it[leftBy].subMap(keys).values() + it }\n// Extract desired keys from the right map, located at `rightBy`, and prepend them.\n// Also drop the map itself from the right.\ndef newRight = right.map {\nit[rightBy].subMap(keys).values() +\nit[0..&lt;rightBy] +\nit[rightBy&lt;..&lt;it.size()]\n}\n// Set the positions to join on explicitly.\njoinArgs.by = 0..&lt;keys.size()\n// Apply the join channel operator to the channels and finally drop the keys used for joining tuples.\nreturn newLeft.join(joinArgs, newRight).map { it[keys.size()..&lt;it.size()] }\n}\n}\n</code></pre> <ol> <li> <p>My current hypothesis is that when you start a new pipeline, the different channels point to the same map object, whereas when you resume, different instances of the map with the same content are created. Then, I guess the comparison carried out by nextflow to join channels, is based on the object identity rather than comparing all key, value pairs.\u00a0\u21a9</p> </li> </ol>"},{"location":"gotchas/process-selector-warn/","title":"No process matching config selector warnings","text":""},{"location":"gotchas/process-selector-warn/#problem","title":"Problem","text":"<p>You are using a process twice in a pipeline in two different subworkflows. Additionally, both are optional to run, so you wrap them in <code>if</code> statements.</p> <pre><code>if ( params.run_module ) {\nPROCESS ()\n}\n</code></pre> <p>You may need to provide each of them different <code>publishDir</code> options so to disambiguate between the two in a configuration file, you differentiate them using a <code>withName</code> selector and give them the fully resolved path name <code>PIPELINE:WORKFLOW:SUBWORKFLOW:PROCESS</code>.</p> conf/modules.config<pre><code>process {\nwithName: 'PIPELINE:WORKFLOW:SUBWORKFLOW_ONE:PROCESS' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_ONE\" },\n]\n}\nwithName: 'PIPELINE:WORKFLOW:SUBWORKFLOW_TWO:PROCESS' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_TWO\" },\n]\n}\n}\n</code></pre> <p>This should be sufficient to distinguish between the two, right?</p> <p>But then when you run your pipeline, with the <code>if</code> statement around the module set to <code>false</code></p> <pre><code>nextflow run main.nf --run_module false\n</code></pre> <p>You suddenly get the following warnings:</p> <pre><code>WARN: There's no process matching config selector: &lt;PIPELINE&gt;:&lt;WORKFLOW&gt;:&lt;SUBWORKFLOW_ONE&gt;:&lt;PROCESS&gt;\nWARN: There's no process matching config selector: &lt;PIPELINE&gt;:&lt;WORKFLOW&gt;:&lt;SUBWORKFLOW_TWO&gt;:&lt;PROCESS&gt;\n</code></pre> <p>...huh? </p> <p>You can see the problem for yourself in an actual pipeline by using GitPod or getting a copy of the project and navigating to <code>examples/process-selector-warn</code>. Where you execute the following command:</p> <pre><code>nextflow -c conf/problem.config run main.nf --skip_hello\n</code></pre>"},{"location":"gotchas/process-selector-warn/#solution","title":"Solution","text":"<p>Apparently, the different ways of specifying a module using the <code>withName</code> selector have different behaviours.</p> <ul> <li>Only an explicit module name can cope with 'optional' execution and have a selector still picked up, even if it's 'turned off'.</li> <li>Fully resolved paths or wildcarded <code>withName</code> selectors cannot be evaluated by Nextflow in this manner, and thus give you warnings like above.</li> </ul> <p>Here, your solutions are:</p> <ol> <li> <p>Give each of the two processes a unique name via an alias and use that in the configuration file.</p> subworkflows/subworkflow_one.nf<pre><code>include { PROCESS as PROCESS_ONE } from 'modules/process_module'\n</code></pre> subworkflows/subworkflow_two.nf<pre><code>include { PROCESS as PROCESS_TWO } from 'modules/process_module'\n</code></pre> conf/modules.config<pre><code>process {\nwithName: 'PROCESS_ONE' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_ONE\" },\n]\n}\nwithName: 'PROCESS_TWO' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_TWO\" },\n]\n}\n}\n</code></pre> </li> <li> <p>Make the <code>withName</code> selector for the module also conditional in the configuration file:</p> conf/modules.config<pre><code>process {\nif ( param.run_module ) {\nwithName: 'PIPELINE:WORKFLOW:SUBWORKFLOW_ONE:PROCESS' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_ONE\" },\n]\n}\nwithName: 'PIPELINE:WORKFLOW:SUBWORKFLOW_TWO:PROCESS' {\npublishDir = [\npath: { \"${params.outdir}/PROCESS_TWO\" },\n]\n}\n}\n}\n</code></pre> </li> </ol> <p>You can see the solution for yourself in an actual pipeline by using GitPod or getting a copy of the project and navigating to <code>examples/process-selector-warn</code>. Where you execute the following command:</p> <pre><code>nextflow -c conf/solution.config run main.nf --skip_hello\n</code></pre>"},{"location":"gotchas/script-order-of-operators/","title":"Ordering of operators in a script","text":""},{"location":"gotchas/script-order-of-operators/#problem","title":"Problem","text":"<p>In many cases, the order in which you define steps of a Nextflow script does not influence the order of execution. This is due to the nature of the process and channel dataflow paradigm used by Nextflow. In contrast, where a Nextflow operator is placed within a script does influence when it is executed.</p> <p>One such example is the <code>mix</code>ing of channels together prior to passing it to a process. If a <code>.mix()</code> is called after the execution of a process that uses that channel, the contents of that particular <code>.mix()</code> will not be included in the execution of the process.</p> <p>A good example of this is nf-core version reporting. In nf-core pipelines, a 'common' channel (<code>ch_versions</code>) is created early in the pipeline script. When each process is executed, a versions file from that process is then mixed into this common channel. Finally, this common channel containing all versions files is sent to a process (<code>CUSTOM_DUMPSOFTWAREVERSIONS</code>) that aggregates all versions into a single file.</p> <p>In the example below, mixing the <code>BAR</code> process' version file into <code>ch_versions</code> is defined to happen after <code>CUSTOM_DUMPSOFTWAREVERSIONS</code>. In this case, the version of <code>BAR</code> would not be included in the execution of the <code>CUSTOM_DUMPSOFTWAREVERSIONS</code> process.</p> <pre><code>ch_versions = Channel.empty()\nFOO()\nBAR()\nch_versions = ch_versions.mix( FOO.out.versions )\nCUSTOM_DUMPSOFTWAREVERSIONS( ch_versions )\nch_versions = ch_versions.mix( BAR.out.versions )\n</code></pre> <p>The output file of <code>CUSTOM_DUMPSOFTWAREVERSIONS</code> would look like</p> <pre><code>FOO:\n  foo: '1.0.0'\n</code></pre> <p>whereby the <code>BAR</code> version is not included in the file.</p>"},{"location":"gotchas/script-order-of-operators/#solution","title":"Solution","text":"<p>Ensure that all <code>mix</code> invocations are defined in the script prior to the subsequent process the channel will be included in.</p> <pre><code>ch_versions = Channel.empty()\nFOO()\nBAR()\nch_versions = ch_versions.mix( FOO.out.versions )\nch_versions = ch_versions.mix( BAR.out.versions )\nCUSTOM_DUMPSOFTWAREVERSIONS ( ch_versions )\n</code></pre> <p>In this case the versions of both FOO and BAR will be displayed </p> <pre><code>FOO:\n  foo: '1.0.0'\nBAR:\n  bar: '2.0.0'\n</code></pre>"},{"location":"gotchas/shallow-copy/","title":"Modifying mutable elements","text":""},{"location":"gotchas/shallow-copy/#problem","title":"Problem","text":"<p>When working with nf-core modules, a ubiquitous pattern is to pass around sample metadata as a maps. Maps are mutable objects. In nextflow DSL2, you can reuse a channel. This creates a shallow copy of the channel's elements which can lead to surprising behavior in combination with mutable objects.</p> <p>To see this in action run the first example.</p> echo.nf<pre><code>process ECHO {\ninput:\nval meta\noutput:\nval meta\n\"\"\"\n    echo '${meta.id}'\n    \"\"\"\n}\n</code></pre> problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Import processes\n ******************************************************************************/\ninclude {\nECHO as ECHO1;\nECHO as ECHO2;\n} from './echo'\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\ndef ch_input = Channel.of([id: 'test1', idx: 1], [id: 'test2', idx: 2])\nECHO1(ch_input).view()\nECHO2(\nch_input.map { meta -&gt;\nmeta.id = 'foo'\nmeta\n}\n).view()\n}\n</code></pre> <p>Notice that we are modifying the <code>id</code> attribute of the maps.</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/shallow-copy/problem.nf\n</code></pre> <pre><code>executor &gt;  local (4)\n[10/bbc389] process &gt; ECHO1 (2) [100%] 2 of 2 \u2714\n[fa/3f7585] process &gt; ECHO2 (2) [100%] 2 of 2 \u2714\n[id:foo, idx:1]\n[id:foo, idx:1]\n[id:foo, idx:2]\n[id:foo, idx:2]\n</code></pre> <p>The channel <code>ch_input</code> contains two elements which are both maps. The channel is passed to a process <code>ECHO1</code> and then reused and modified before being passed to the process <code>ECHO2</code>. Intuitively, we would expect the reuse to copy the channel and thus be independent of the first use. However, due to nextflow being asynchronous and shallow copying the channels, we can see that all maps are modified.</p>"},{"location":"gotchas/shallow-copy/#solution","title":"Solution","text":"<p>In order to achieve the desired outcome of the reused channel being independent of the first use, we need to clone the mutable element. This then creates a shallow of the mutable element itself which can be modified independently.</p> problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Import processes\n ******************************************************************************/\ninclude {\nECHO as ECHO1;\nECHO as ECHO2;\n} from './echo'\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\ndef ch_input = Channel.of([id: 'test1', idx: 1], [id: 'test2', idx: 2])\nECHO1(ch_input).view()\nECHO2(\nch_input.map { meta -&gt;\ndef copy = meta.clone()\ncopy.id = 'foo'\nreturn copy\n}\n).view()\n}\n</code></pre> <p>To see the outcome, run the following:</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/shallow-copy/solution.nf\n</code></pre> <pre><code>executor &gt;  local (4)\n[0e/0b1e55] process &gt; ECHO1 (1) [100%] 2 of 2 \u2714\n[f6/4e9656] process &gt; ECHO2 (2) [100%] 2 of 2 \u2714\n[id:foo, idx:1]\n[id:test2, idx:2]\n[id:test1, idx:1]\n[id:foo, idx:2]\n</code></pre> <p>In some cases where you have nested mutable objects you may have to create a deep copy.</p>"},{"location":"gotchas/shell-global-only/","title":"Global variables only in shell blocks","text":""},{"location":"gotchas/shell-global-only/#problem","title":"Problem","text":"<p>A very common pattern when working with nf-core modules is to define local arguments for a command. This pattern allows for defining some process-local defaults, as well as the ability to override those defaults from a configuration file.</p> <p>Take the gunzip module, for example, it defines empty default arguments.</p> gunzip/main.nf<pre><code>process GUNZIP {\ntag \"$archive\"\nlabel 'process_low'\nconda (params.enable_conda ? \"conda-forge::sed=4.7\" : null)\ncontainer \"${ workflow.containerEngine == 'singularity' &amp;&amp; !task.ext.singularity_pull_docker_container ?\n        'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' :\n        'biocontainers/biocontainers:v1.2.0_cv1' }\"\ninput:\ntuple val(meta), path(archive)\noutput:\ntuple val(meta), path(\"$gunzip\"), emit: gunzip\npath \"versions.yml\"             , emit: versions\nwhen:\ntask.ext.when == null || task.ext.when\nscript:\ndef args = task.ext.args ?: ''\ngunzip = archive.toString() - '.gz'\n\"\"\"\n    gunzip \\\\\n        -f \\\\\n        $args \\\\\n        $archive\n    cat &lt;&lt;-END_VERSIONS &gt; versions.yml\n    \"${task.process}\":\n        gunzip: \\$(echo \\$(gunzip --version 2&gt;&amp;1) | sed 's/^.*(gzip) //; s/ Copyright.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}\n</code></pre> <p>I can then override the default arguments with additional options in a configuration file such as a pipeline's <code>conf/modules.config</code>.</p> conf/modules.config<pre><code>process {\nwithName: GUNZIP {\next.args = '--keep'\n}\n}\n</code></pre> <p>The other day, I needed to use a shell block instead of the normal script block but I hit a snag; my <code>args</code> were being replaced with <code>[]</code>?!  You can try this yourself by running the following workflow.</p> problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\necho true\nshell:\ndef args = task.ext.args ?: 'bar'\nlog.info \"\"\"\n    ${task.process}: task.ext.args: ${task.ext.args}\n    ${task.process}: args: ${args}\n    \"\"\"\n'''\n    echo !{args}\n    '''\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nECHO()\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/shell-global-copy/problem.nf\n</code></pre> <p>When you do so, you should see output like:</p> <pre><code>executor &gt;  local (1)\n[97/a1e136] process &gt; ECHO [100%] 1 of 1 \u2714\n    ECHO: task.ext.args: null\n    ECHO: args: bar\n[]\n</code></pre> <p>As you will see from the output, <code>args</code> contains the correct value <code>bar</code> but the final output is <code>[]</code>.</p>"},{"location":"gotchas/shell-global-only/#exploration","title":"Exploration","text":"<p>That made me wonder, \"Is the <code>args</code> variable special somehow?\"  The name is easily changed to <code>foo</code> which you can try yourself.</p> exploration.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\nprocess ECHO {\necho true\nshell:\ndef foo = task.ext.args ?: 'bar'\nlog.info \"\"\"\n    ${task.process}: task.ext.args: ${task.ext.args}\n    ${task.process}: foo: ${args}\n    \"\"\"\n'''\n    echo !{foo}\n    '''\n}\nworkflow {\nECHO()\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/shell-global-copy/exploration.nf\n</code></pre> <p>And  big, fat error.</p> <pre><code>Error executing process &gt; 'ECHO_LOCAL_FOO'\nCaused by:\n  No such variable: foo\nSource block:\n  def foo = task.ext.args ?: 'bar'\n  log.info \"\"\"\n      ${task.process}: task.ext.args: ${task.ext.args}\n      ${task.process}: foo: ${foo}\n      \"\"\"\n  '''\n      echo !{foo}\n      '''\n</code></pre> <p>This was the clue I needed to find a solution.</p>"},{"location":"gotchas/shell-global-only/#solution","title":"Solution","text":"<p>There are a couple of gotchas in nextflow with locally scoped variables (variables defined with <code>def</code>). So why not try with a process global? Removing the <code>def</code> keyword finally made the process run as expected. You can see for yourself by running the following:</p> solution.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\nprocess ECHO {\necho true\nshell:\nargs = task.ext.args ?: 'bar'\nlog.info \"\"\"\n    ${task.process}: task.ext.args: ${task.ext.args}\n    ${task.process}: args: ${args}\n    \"\"\"\n'''\n    echo !{args}\n    '''\n}\nworkflow {\nECHO()\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/shell-global-copy/solution.nf\n</code></pre> <pre><code>executor &gt;  local (1)\n[ba/0e5d39] process &gt; ECHO [100%] 1 of 1 \u2714\n    ECHO: task.ext.args: null\n    ECHO: args: bar\nbar\n</code></pre> <p>Smooth </p>"},{"location":"gotchas/singleton-channel/","title":"Exhausting single element channels","text":""},{"location":"gotchas/singleton-channel/#problem","title":"Problem","text":"<p>Processes that accept more than one argument, will be executed as many times as the smaller number of elements in either channel, for example, if you have a channel with five elements and another with two elements, the process will be called twice. If you have a channel with a single element, it is not reused automatically but the process is executed just once. This can be surprising because nextflow in DSL2 copies channels as needed.</p> problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\ninput:\nval(number)\nval(data)\n\"\"\"\n    echo ${number}-${data}\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_variadic = Channel.of(1..20)\nch_singleton = Channel.of('arg')\nECHO(ch_variadic, ch_singleton)\n}\n</code></pre> <p>Run the above workflow with:</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/singleton-channel/problem.nf\n</code></pre> <p>which gives the following output, the process is just called once.</p> <pre><code>executor &gt;  local (1)\n[b5/7c55cf] process &gt; ECHO (1) [100%] 1 of 1 \u2714\n</code></pre>"},{"location":"gotchas/singleton-channel/#solution","title":"Solution","text":"<p>Channels can be turned into value channels which can never be exhausted and read an unlimited number of times. A simple way to do this is by applying the operator <code>first</code>.</p> solution.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\ninput:\nval(number)\nval(data)\n\"\"\"\n    echo ${number}-${data}\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_variadic = Channel.of(1..20)\nch_singleton = Channel.of('arg')\nECHO(ch_variadic, ch_singleton.first())\n}\n</code></pre> <p>You can see the difference by running the workflow.</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/singleton-channel/solution.nf\n</code></pre> <pre><code>executor &gt;  local (20)\n[02/fa180f] process &gt; ECHO (20) [100%] 20 of 20 \u2714\n</code></pre> <p>Please note the following admonition from the nextflow documentation:</p> <p>Note</p> <p>A value channel is implicitly created by a process when an input specifies a simple value in the <code>from</code> clause. Moreover, a value channel is also implicitly created as output for a process whose inputs are only value channels.</p> <p>This means that a process that gets passed a value and, for example, downloads a file, implicitly has a value channel created for that file and it can be reused indefinitely.</p>"},{"location":"gotchas/singleton-channel/#combinations","title":"Combinations","text":"<p>If you have multiple channels of different numbers of elements but more than one element such that a value channel is not an option, you can apply some transformations to achieve the correct outcome.</p> combinations.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\ninput:\nval(number)\nval(data)\n\"\"\"\n    echo ${number}-${data}\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nch_long = Channel.of(1..20)\nch_short = Channel.of(31..33)\nch_combined = ch_long\n.combine(ch_short)\n.multiMap {\nfirst: it[0]\nsecond: it[1]\n}\nECHO(ch_combined.first, ch_combined.second)\n}\n</code></pre> <p>In this workflow, <code>combine</code> does most of the work, as it combines each element from one channel with every element of the other channel. Afterwards, we use <code>multiMap</code> to split the pairs into two separate channels that we can pass to the process which expects two arguments.</p> <p>You can see the difference by running the workflow.</p> <pre><code>NXF_VER='21.10.6' nextflow run examples/singleton-channel/combinations.nf\n</code></pre> <p>Combinatorics, wheee</p> <pre><code>executor &gt;  local (60)\n[09/71172f] process &gt; ECHO (60) [100%] 60 of 60 \u2714\n</code></pre>"},{"location":"gotchas/variable-scope/","title":"Variable scope","text":"<p>Under most circumstances it is recommended to use local variable scope. In Groovy and thus nextflow, you do this with the <code>def</code> keyword. However, there are some situations where this can be awkward or even surprising.</p>"},{"location":"gotchas/variable-scope/#conditionals","title":"Conditionals","text":"<p>In the following workflow, the variable <code>message</code> is declared local to the <code>if</code> statement and cannot be accessed outside it. </p> if.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nif (true) {\ndef message = 'Hello... noone?'\n}\ndef ch = Channel.of(message)\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/variable-scope/if.nf\n</code></pre> <pre><code>No such variable: message\n -- Check script 'examples/variable-scope/problem.nf' at line: 13 or see '.nextflow.log' file for more details\n</code></pre>"},{"location":"gotchas/variable-scope/#process-blocks","title":"Process blocks","text":""},{"location":"gotchas/variable-scope/#problem","title":"Problem","text":"<p>In my mental model, a nextflow process is very much a logical unit. However, a process consists of up to five blocks and variables local to one block, cannot be used in another. As an example:</p> process-problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess TOUCH {\ninput:\nval(meta)\noutput:\ntuple val(meta), path(result)\nscript:\ndef result = \"${meta.id}.txt\"\n\"\"\"\n    touch '${result}'\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nTOUCH([id: 'snafu'])\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/variable-scope/process-problem.nf\n</code></pre> <pre><code>executor &gt;  local (1)\n[28/98c503] process &gt; TOUCH [100%] 1 of 1, failed: 1 \u2718\nError executing process &gt; 'TOUCH'\nCaused by:\n  Missing output file(s) `result` expected by process `TOUCH`\nCommand executed:\n  touch 'snafu.txt'\nCommand exit status:\n  0\nCommand output:\n  (empty)\n</code></pre>"},{"location":"gotchas/variable-scope/#solution","title":"Solution","text":"<p>It is an error to use the <code>result</code> variable which was declared local to the <code>script</code> block, in any other block. One may want to use a variable defined in the <code>script</code> block in the <code>output</code> block. In that case, you have to remove the <code>def</code> keyword to make it global.</p> process-solution.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess TOUCH {\ninput:\nval(meta)\noutput:\ntuple val(meta), path(result)\nscript:\nresult = \"${meta.id}.txt\"\n\"\"\"\n    touch '${result}'\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nTOUCH([id: 'snafu'])\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/variable-scope/process-solution.nf\n</code></pre> <pre><code>executor &gt;  local (1)\n[f4/263762] process &gt; TOUCH [100%] 1 of 1 \u2714\n</code></pre>"},{"location":"gotchas/variable-scope/#mixing-variables","title":"Mixing variables","text":"<p>Additionally, if you use a variable with global scope in the assignment of a variable with local scope, this is also an error.</p> mixing-problem.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\ninput:\nval(meta)\noutput:\ntuple val(meta), path(result)\nscript:\nresult = \"${meta.id}.txt\"\ndef choice = result.startsWith('snafu') ? 'yes' : 'no'\n\"\"\"\n    echo '${choice}' &gt; '${result}'\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nECHO([id: 'snafu'])\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/variable-scope/mixing-problem.nf\n</code></pre> <pre><code>Script compilation error\n- cause: Variable `result` already defined in the process scope @ line 19, column 18.\n       def choice = result.startsWith('snafu') ? 'yes' : 'no'\n                    ^\n</code></pre> <p>That means, any variable that uses a global in its assignment, has to be global also.</p> mixing-solution.nf<pre><code>#!/usr/bin/env nextflow\nnextflow.enable.dsl = 2\n/*******************************************************************************\n * Define processes\n ******************************************************************************/\nprocess ECHO {\ninput:\nval(meta)\noutput:\ntuple val(meta), path(result)\nscript:\nresult = \"${meta.id}.txt\"\nchoice = result.startsWith('snafu') ? 'yes' : 'no'\n\"\"\"\n    echo '${choice}' &gt; '${result}'\n    \"\"\"\n}\n/*******************************************************************************\n * Define main workflow\n ******************************************************************************/\nworkflow {\nECHO([id: 'snafu'])\n}\n</code></pre> <pre><code>NXF_VER='21.10.6' nextflow run examples/variable-scope/mixing-solution.nf\n</code></pre> <pre><code>executor &gt;  local (1)\n[c2/70f706] process &gt; ECHO [100%] 1 of 1 \u2714\n</code></pre> <p>Hope this helps, it can be quite baffling.</p>"}]}